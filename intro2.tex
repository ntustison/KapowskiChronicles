\section{Introduction}

Magnetic resonance imaging-based 
structural analysis of the human brain plays a fundamental role
in identifying the relationship between cortical morphology, disease, and cognition.
Discriminative cortical thickness values 
have been demonstrated in normal aging \citep{Lemaitre2012,Chen2011,kochunov2011,Walhovd2013} and in gender \citep{amunts2007,luders2006a}.
Thickness is also sensitive to conditional abnormalities such as
Huntington's disease \citep{rosas2002,rosas2005,selemon2004}, 
schizophrenia \citep{nesvag2008}, bipolar disorder \citep{lyoo2006}, Alzheimer's disease and frontotemporal
dementia \citep{du2007,dickerson2009}, Parkinson's disease \citep{jubault2011}, Williams syndrome \citep{thompson2005},
multiple sclerosis \citep{ramasamy2009}, autism \citep{chung2005,hardan2006},
migraines \citep{dasilva2007}, chronic smoking \citep{kuhn2010}, alcoholism \citep{fortier2011},
cocaine \citep{makris2008} and heroin \citep{li2014} addiction, Tourette syndrome in children \citep{sowell2008},
scoliosis in
female adolescents \citep{wang2012}, 
early-onset blindness \citep{jiang2009},
chronic pancreatitis \citep{frokjaer2012},
obsessive-compulsive disorder \citep{shin2007}, ADHD \citep{almeida-montes2012}, obesity \citep{raji2010}, 
and heritable \citep{peterson2009}
and elderly \citep{ballmaier2004} depression.  Evidence of cortical thickness 
variation has also been found in untreated
male-to-female transsexuality \citep{luders2012},  handedness
\citep{luders2006,amunts2007}, intelligence \citep{shaw2006}, athletic
ability \citep{wei2011}, meditative practices \citep{lazar2005}, musical ability \citep{bermudez2009,foster2010}, 
tendency toward criminality \citep{raine2011}, 
childhood sexual abuse in adult females \citep{heim2013},
and Tetris-playing
ability in female adolescents \citep{haier2009}.  Additionally,
recent studies demonstrate correlated anatomical
relationships using cortical thickness measures
\citep{worsley2005,lerch2006,he2007,chen2008}.
Although these findings
are subject to debate and interpretation \citep{gernsbacher2007}, 
the availability of quantitative
computational methods for extracting a measure of cortical thickness
has proven invaluable for developing and refining fundamental 
neuroscience hypotheses.

Computational methods for analyzing the cortex may be 
broadly characterized as surface mesh-based or volumetric \citep{scott2009,clarkson2011}.  Representative of the former is the
FreeSurfer%
\footnote{
http://surfer.nmr.mgh.harvard.edu/
}
cortical modeling software package \citep{dale1999,fischl1999,fischl2000,fischl2002,fischl2004}
which owes its popularity to public availability, excellent documentation, 
good performance, and integration with other toolkits, such as the extensive FMRIB software 
library (FSL) \citep{smith2004}.  Similar to other surface-based cortical thickness estimation
approaches (e.g., \cite{davatzikos1996,magnotta1999,macdonald2000,kim2005}), the outer cortical
and gray/white matter surfaces from individual subject MR data are modeled with polygonal meshes
which are then used to determine local cortical thickness values based on a specified correspondence between 
the surface models.

Image volumetric (or meshless) techniques vary both in their algorithms as well as
in the underlying definitions of cortical thickness.  An early, foundational technique is the
method of \cite{jones2000} in which the inner and outer surface geometry is used to determine the
solution to Laplace's equation where thickness is measured by integrating along the 
tangents of the resulting field lines spanning the boundary surfaces.  Subsequent contributions
improved upon the original formulation.  For example, in \cite{yezzi2003}, a Eulerian partial differential equation approach
was proposed to facilitate the computation of correspondence paths.  Extending the surface-based
work of \cite{macdonald2000}, the hybrid approach of
\cite{kim2005} uses the discrete Laplacian field to deform the white matter surface mesh towards the 
outer cortical surface.    Although the Laplacian-based approach has several advantages
including generally lower computation times and
non-crossing correspondence paths, direct correlative assessments with histology
are potentially problematic as the quantified distances 
are not necessarily Euclidean.  Other volumetric algorithms employ coupled
level sets \citep{zeng1999}, model-free intelligent search strategies either normal to 
the gray-white matter interface \citep{scott2009}, or using a min-max rule \citep{clement-vachet2011}.
Most relevant to this work is the DiReCT (Diffeomorphic Registration-based 
Cortical Thickness) algorithm proposed in \cite{das2009} where generated
diffeomorphic mappings between the 
gray/white matter and exterior cortical surfaces are used to propagate thickness values
through the cortical gray matter.  A unique benefit of DiReCT is that it
naturally estimates the boundaries of buried sulci by employing a
diffeomorphic constraint on the probabilistic estimate of the gray
matter and cerebrospinal fluid interface.  

%Although a variety of techniques exist for estimating cortical
%thickness from imaging data (of which only a fraction are cited here),
%several common preprocessing components can be identified.  The most
%fundamental of these include inhomogeneity correction, skull
%stripping, and $n$-tissue segmentation for differentiating gray and
%white matter.  For statistical analysis across large populations,
%construction of population-specific unbiased templates is also
%potentially beneficial \citep{evans2012}.  In addition, intermediate
%steps might include a crucial registration component (e.g.,
%propagating template-based tissue priors for improved segmentation \citep{ashburner2005}).

%Cortical thickness studies are made more complex by the need for large
%neuroimaging data sets such as that provided by the Alzheimer's
%Disease Neuroimaging Initiative (ADNI) \citep{Weiner2012} and the need
%for packaging of state-of-the-art research methods so that other
%researchers can more easily use them.  Currently, the National
%Institutes of Health (NIH) mandates that any NIH-funded data
%resources, including MRI, must be released to the public.  In contrast
%to ADNI, which provides standardized data acquisition protocols used
%across all sites, these smaller-scale projects are collected in an
%unstructured way.  Therefore, neuroimage processing tools must
%work reliably even when there is a relative lack of quality
%control over the input data.  While robustness is a goal shared by all
%software development targeted at neuroscience research, very few
%methods have been thoroughly tested on large and unstructured
%neuroimaging data sets.


The general lack of availability of published
algorithms \citep{kovacevic2006} (not to mention critical preprocessing
components) is a strong deterrent to the use or evaluation of these algorithms
by external researchers.  For example, one recent evaluation
study \citep{clarkson2011} compared
FreeSurfer (a surface-based method) with two volumetric methods, viz., \cite{jones2000,das2009}.
Whereas the entire FreeSurfer processing pipeline has been made publicly available, 
refined by the original authors and other contributors, and described in great detail 
(specifically in terms of suggested parameters), both volumetric methods were
implemented and run by the authors of the evaluation (not by the algorithm developers)
using unspecified parameters with relatively small, private data sets,
making the comparisons less than ideal (see \cite{tustison2013} for further discussion
concerning the issue of instrumentation bias and scientific reproducibility in the use and evaluation of software).
Further complicating such comparisons is the potential for bias, such as interpolation artifacts when
converting surface to volume data or vice versa \citep{klein2010}.

We provide below a brief description of our proposed pipeline, which produces a volumetric
cortical thickness map from an individual subject's T1-weighted MRI.
Additionally, we note that it is freely available as part of the Advanced Normalization Tools
(ANTs) software package\footnote{\href{http://stnava.github.io/ANTs/}{http://stnava.github.io/ANTs/}}.  This includes all the necessary preprocessing steps consisting
of well-vetted, previously published algorithms for bias correction \citep{tustison2010},
brain extraction \citep{avants2010a}, $n$-tissue segmentation \citep{avants2011a},
template construction \citep{avants2010}, and image normalization \citep{avants2011}.
More importantly, we provide explicit coordination among
these components within a set of well-documented shell scripts%
\footnote{
Ongoing improvements in documentation can be found in the form of online tutorials, 
self-contained github examples, and the ANTs discussion forums.
}
which are also available in the ANTs repository where parameters have been tuned
by ANTs developers (N.T. and B.A.).  

Here we demonstrate the use of the described framework in processing
1205 publicly available, T1-weighted brain MR images drawn from four
well-known data sets.  For comparative evaluation we also process the
same data using the standard FreeSurfer cortical thickness processing
protocol.  Similar to previous work \citep[e.g.,][]{clarkson2011}, we
are able to report repeatability assessments for both frameworks using
subsets of the data with repeated acquisitions.
However, repeatability (or, more generally, {\it precision}) is not
conceptually equivalent to {\it accuracy} and, thus, does not provide
a complete perspective for determination of measurement quality.
Although FreeSurfer validation has included histological
\citep{rosas2002} and image-drawn \citep{kuperberg2003} comparisons,
such manual assessments were extremely limited in terms of number of
subjects and the number of cortical regions.  In addition, there was
no mention in these studies of the number of human observers making
these measurements nor discussion of quality assurance.
Alternatively, without ground truth other forms of evidence can be
adduced \citep[e.g.,][]{bouix2007} in making comparative inferences.
In this work we use demographic-based assessments 
(based on well-studied relationships between cortical thickness
and age/gender) to show that ANTs outperforms FreeSurfer-based thickness 
estimation for these data in terms of prediction.

%Finally, we make available all data from both ANTs and FreeSurfer 
%processing outcomes.  This includes derived image data, processing scripts, 
%and tabulated results.  The availability of both the code and data enables
%the set of results described in this work to be fully reproducible.  
